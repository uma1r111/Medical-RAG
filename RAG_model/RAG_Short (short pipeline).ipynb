{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ed49ebce6cc34bb3a49dc716044bc790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bffc48d28d3a46ee93c1c8e7a671846a",
              "IPY_MODEL_515ded45ed334f3eab1ecca7570b73e7",
              "IPY_MODEL_b6ef8a75f5b544839c0ead7de3eb74f9"
            ],
            "layout": "IPY_MODEL_caaac6844d6445738daf7af32fa8a236"
          }
        },
        "bffc48d28d3a46ee93c1c8e7a671846a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c34cdaae37d24d128b057d0ea1fad61c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c3b98ade712444ebbb582b51665bf305",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "515ded45ed334f3eab1ecca7570b73e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_549ce091d4004409923587e3ef6a28cc",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f629f73f8ca49409cf1f93ed4b780d9",
            "value": 2
          }
        },
        "b6ef8a75f5b544839c0ead7de3eb74f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0295b53e2900411f972346adf09d0e0c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0623263c9b2143a7b82d1df4d31c7c69",
            "value": "‚Äá2/2‚Äá[00:00&lt;00:00,‚Äá‚Äá3.04it/s]"
          }
        },
        "caaac6844d6445738daf7af32fa8a236": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c34cdaae37d24d128b057d0ea1fad61c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3b98ade712444ebbb582b51665bf305": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "549ce091d4004409923587e3ef6a28cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f629f73f8ca49409cf1f93ed4b780d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0295b53e2900411f972346adf09d0e0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0623263c9b2143a7b82d1df4d31c7c69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dpHLVPbBoaJw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a1359f8-6677-49f7-9b8b-f9cd30f94de5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.4.0)\n",
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.11/dist-packages (0.2.2)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.21)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.52)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.31)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain faiss-cpu sentence-transformers transformers datasets pypdf rank_bm25 -U langchain-community\n",
        "\n",
        "\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from rank_bm25 import BM25Okapi\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoModelForCausalLM\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "import numpy as np\n",
        "import csv, os, re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "SWY59wEFof5g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "68b803a6-a3df-48ea-f859-b28ce7d54850"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7dd52385-ebc3-4535-9638-cb198d89e198\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7dd52385-ebc3-4535-9638-cb198d89e198\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 13. Atlas of Diabetes Mellitus (3rd Edition).pdf to 13. Atlas of Diabetes Mellitus (3rd Edition) (1).pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "from langchain.schema import Document\n",
        "import re\n",
        "\n",
        "# üìÑ Load and Preprocess PDF\n",
        "pdf_path = \"/content/13. Atlas of Diabetes Mellitus (3rd Edition).pdf\"\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "documents = loader.load()\n",
        "\n",
        "# üßπ Clean text and add metadata\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespace/newlines\n",
        "    text = re.sub(r'\\.([A-Z])', r'. \\1', text)  # Fix spacing after periods\n",
        "    return text.strip()\n",
        "\n",
        "for doc in documents:\n",
        "    doc.page_content = clean_text(doc.page_content)\n",
        "    doc.metadata[\"source_file\"] = os.path.basename(pdf_path)\n",
        "\n",
        "# üß† Choose chunking strategy: \"recursive\", \"sentence\", or \"paragraph\"\n",
        "chunking_strategy = \"recursive\"   # Change this to \"sentence\" or \"paragraph\" if needed\n",
        "chunk_size = 500\n",
        "chunk_overlap = 200\n",
        "\n",
        "chunks = []\n",
        "\n",
        "if chunking_strategy == \"recursive\":\n",
        "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    chunks = splitter.split_documents(documents)\n",
        "\n",
        "elif chunking_strategy == \"sentence\":\n",
        "    for doc in documents:\n",
        "        sentences = sent_tokenize(doc.page_content)\n",
        "        current_chunk = []\n",
        "        current_length = 0\n",
        "        for sent in sentences:\n",
        "            if current_length + len(sent) > chunk_size:\n",
        "                chunk_text = \" \".join(current_chunk)\n",
        "                chunks.append(Document(page_content=chunk_text, metadata=doc.metadata))\n",
        "                current_chunk = current_chunk[-(chunk_overlap // len(sent) + 1):]  # Simple overlap\n",
        "                current_length = sum(len(s) for s in current_chunk)\n",
        "            current_chunk.append(sent)\n",
        "            current_length += len(sent)\n",
        "        if current_chunk:\n",
        "            chunks.append(Document(page_content=\" \".join(current_chunk), metadata=doc.metadata))\n",
        "\n",
        "elif chunking_strategy == \"paragraph\":\n",
        "    for doc in documents:\n",
        "        paragraphs = re.split(r'\\n\\s*\\n', doc.page_content)\n",
        "        current_chunk = []\n",
        "        current_length = 0\n",
        "        for para in paragraphs:\n",
        "            para = para.strip()\n",
        "            if not para:\n",
        "                continue\n",
        "            if current_length + len(para) > chunk_size:\n",
        "                chunks.append(Document(page_content=\"\\n\\n\".join(current_chunk), metadata=doc.metadata))\n",
        "                current_chunk = current_chunk[-1 * (chunk_overlap // len(para) + 1):]\n",
        "                current_length = sum(len(p) for p in current_chunk)\n",
        "            current_chunk.append(para)\n",
        "            current_length += len(para)\n",
        "        if current_chunk:\n",
        "            chunks.append(Document(page_content=\"\\n\\n\".join(current_chunk), metadata=doc.metadata))\n",
        "\n",
        "else:\n",
        "    raise ValueError(\"Invalid chunking strategy selected.\")\n",
        "\n",
        "# üìö Extract text\n",
        "texts = [doc.page_content for doc in chunks]\n",
        "print(f\"‚úÖ Chunking complete using '{chunking_strategy}' ‚Äî Total chunks: {len(chunks)}\")\n"
      ],
      "metadata": {
        "id": "auk1E2Jpofo1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "354fd0f6-6bfd-4235-ec4b-79a9de907f39"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Chunking complete using 'recursive' ‚Äî Total chunks: 930\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dense: PubMedBERT + FAISS\n",
        "embedding_model = HuggingFaceEmbeddings(model_name='pritamdeka/S-PubMedBert-MS-MARCO')\n",
        "vector_store = FAISS.from_texts(texts, embedding_model)\n",
        "\n",
        "# BM25: Sparse\n",
        "tokenized_texts = [text.split(\" \") for text in texts]\n",
        "bm25 = BM25Okapi(tokenized_texts)\n",
        "\n",
        "# SentenceTransformer for encoding query\n",
        "dense_encoder = SentenceTransformer('pritamdeka/S-PubMedBert-MS-MARCO')"
      ],
      "metadata": {
        "id": "5q_PN7XoojDZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarization\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "def summarize_text(text):\n",
        "    return summarizer(text, max_length=100, min_length=30, do_sample=False)[0]['summary_text']\n",
        "\n",
        "# Reorder by query relevance\n",
        "def reorder_by_query(query, context):\n",
        "    query_terms = query.lower().split()\n",
        "    sentences = context.split('. ')\n",
        "    scored = sorted(sentences, key=lambda s: sum(word in s.lower() for word in query_terms), reverse=True)\n",
        "    return '. '.join(scored)\n",
        "\n",
        "# Highlight query terms\n",
        "def highlight_terms(text, query):\n",
        "    for word in query.lower().split():\n",
        "        text = re.sub(fr'\\b{word}\\b', f'[HIGHLIGHT]{word}[/HIGHLIGHT]', text, flags=re.IGNORECASE)\n",
        "    return text\n",
        "\n",
        "# Deduplication\n",
        "def deduplicate(sentences):\n",
        "    unique = []\n",
        "    seen = set()\n",
        "    for s in sentences:\n",
        "        norm = s.strip().lower()\n",
        "        if norm not in seen:\n",
        "            seen.add(norm)\n",
        "            unique.append(s)\n",
        "    return unique\n"
      ],
      "metadata": {
        "id": "EdoVSKItomUU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "325d1416-b7b5-4536-97a7-c99660227636"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"tiiuae/falcon-7b-instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=\"auto\")\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer,\n",
        "                max_new_tokens=256, temperature=0.4, top_k=50, top_p=0.9, repetition_penalty=1.2)\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "id": "lcF7kzc3oojn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "ed49ebce6cc34bb3a49dc716044bc790",
            "bffc48d28d3a46ee93c1c8e7a671846a",
            "515ded45ed334f3eab1ecca7570b73e7",
            "b6ef8a75f5b544839c0ead7de3eb74f9",
            "caaac6844d6445738daf7af32fa8a236",
            "c34cdaae37d24d128b057d0ea1fad61c",
            "c3b98ade712444ebbb582b51665bf305",
            "549ce091d4004409923587e3ef6a28cc",
            "6f629f73f8ca49409cf1f93ed4b780d9",
            "0295b53e2900411f972346adf09d0e0c",
            "0623263c9b2143a7b82d1df4d31c7c69"
          ]
        },
        "outputId": "7a2f8db2-c13b-41ad-8a77-633e9afb055b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed49ebce6cc34bb3a49dc716044bc790"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu and disk.\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hybrid_retrieve(query, top_k=5):\n",
        "    # Sparse\n",
        "    query_tokens = query.lower().split()\n",
        "    bm25_scores = bm25.get_scores(query_tokens)\n",
        "    sparse_indices = np.argsort(bm25_scores)[::-1][:top_k]\n",
        "\n",
        "    # Dense\n",
        "    dense_query = dense_encoder.encode([query], convert_to_numpy=True)[0]\n",
        "    _, dense_indices = vector_store.index.search(np.array([dense_query]), top_k)\n",
        "\n",
        "    # Merge\n",
        "    hybrid_indices = list(set(sparse_indices).union(set(dense_indices[0])))\n",
        "    return [chunks[i] for i in hybrid_indices]\n"
      ],
      "metadata": {
        "id": "fC-r1UwuorVB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EVAL_TEMPLATE = \"\"\"\n",
        "You are an evaluator. Rate the following answer using the source documents provided.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer: {answer}\n",
        "\n",
        "Sources:\n",
        "{sources}\n",
        "\n",
        "Give a score from 1 to 5 for:\n",
        "FAITHFULNESS: Is it consistent with sources?\n",
        "RELEVANCE: Does it answer the question?\n",
        "\n",
        "Format:\n",
        "FAITHFULNESS: <score>, RELEVANCE: <score>\n",
        "\"\"\"\n",
        "\n",
        "def get_auto_scores(llm, question, answer, sources):\n",
        "    combined = \"\\n---\\n\".join([doc.page_content[:500] for doc in sources])\n",
        "    prompt = EVAL_TEMPLATE.format(question=question, answer=answer, sources=combined)\n",
        "    response = llm(prompt)\n",
        "    try:\n",
        "        match = re.search(r\"FAITHFULNESS: (\\d).*RELEVANCE: (\\d)\", response, re.DOTALL)\n",
        "        return int(match.group(1)), int(match.group(2))\n",
        "    except Exception as e:\n",
        "        print(\"‚ö†Ô∏è Eval parse failed:\", e)\n",
        "        return None, None\n",
        "\n",
        "def log_evaluation_to_csv(filepath, question, answer, sources, faithfulness, relevance):\n",
        "    file_exists = os.path.isfile(filepath)\n",
        "    with open(filepath, 'a', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        if not file_exists:\n",
        "            writer.writerow(['Question', 'Answer', 'Sources', 'Faithfulness', 'Relevance'])\n",
        "        src = \"\\n---\\n\".join([doc.page_content[:300] for doc in sources])\n",
        "        writer.writerow([question, answer, src, faithfulness, relevance])\n"
      ],
      "metadata": {
        "id": "U6umJt33ot5a"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test reasoning + hybrid performance\n",
        "query0 = \"What are the main types of diabetes and how are they different?\"\n",
        "query2 = \"What is the difference between hypoglycemia and hyperglycemia?\"\n",
        "\n",
        "# sparse retrieval testing\n",
        "query3 = \"What is the normal range for blood sugar levels?\"\n",
        "query4 = \"How is diabetes diagnosed?\"\n",
        "\n",
        "# dense retrieval testing\n",
        "query5 = \"What complications arise from chronic hyperglycemia?\"\n",
        "\n",
        "# test sequential understanding\n",
        "query6 = \"What is the lifecycle of insulin from secretion to absorption?\"\n",
        "\n",
        "# test embedding quality\n",
        "query7 = \"What does HbA1c mean and why is it important?\"\n",
        "\n",
        "# test noisy input\n",
        "query8 = \"H0w 2 treet dibetes wit diet?\"\n",
        "\n",
        "# role based query\n",
        "query9 = \"Advise a diabetic patient on how to manage their condition while fasting during Ramadan.\"\n",
        "query10 = \"Explain to an elderly patient how exercise can help control blood sugar levels.\"\n",
        "\n",
        "retrieved_docs = hybrid_retrieve(query9)\n",
        "\n",
        "# Preprocess context\n",
        "raw_context = \"\\n\\n\".join([doc.page_content[:500] for doc in retrieved_docs])\n",
        "summarized = summarize_text(raw_context)\n",
        "reordered = reorder_by_query(query9, summarized)\n",
        "highlighted = highlight_terms(reordered, query9)\n",
        "final_context = '. '.join(deduplicate(highlighted.split('. ')))\n",
        "\n",
        "# Generate answer\n",
        "# prompt = f\"Based on the context below, answer the question:\\n\\nContext:\\n{final_context}\\n\\nQuestion: {query}\"\n",
        "# answer = llm(prompt)\n",
        "\n",
        "# Role based\n",
        "prompt = f\"\"\"\n",
        "You are an experienced medical advisor.\n",
        "\n",
        "Based on the following context, answer the patient's question in simple and accurate terms:\n",
        "\n",
        "Context:\n",
        "{final_context}\n",
        "\n",
        "Question:\n",
        "{query9}\n",
        "\"\"\"\n",
        "answer = llm(prompt)\n",
        "\n",
        "\n",
        "print(\"\\nüìù Question:\", query9)\n",
        "print(\"\\n‚úÖ Answer:\\n\", answer)\n",
        "print(\"\\nüìö Retrieved Snippets:\\n\")\n",
        "for i, doc in enumerate(retrieved_docs):\n",
        "    print(f\"Source {i+1}:\\n{doc.page_content[:300]}\\n---\")\n",
        "\n",
        "# Evaluate\n",
        "faithfulness, relevance = get_auto_scores(llm, query9, answer, retrieved_docs)\n",
        "print(f\"\\nü§ñ Auto Evaluation ‚Äî Faithfulness: {faithfulness}, Relevance: {relevance}\")\n",
        "\n",
        "# Log\n",
        "log_evaluation_to_csv(\"rag_results.csv\", query9, answer, retrieved_docs, faithfulness, relevance)"
      ],
      "metadata": {
        "id": "SqqrdM0-o0YK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00cd7ad9-2238-464d-9ff8-785dc33d3a41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.4` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.4` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìù Question: Advise a diabetic patient on how to manage their condition while fasting during Ramadan.\n",
            "\n",
            "‚úÖ Answer:\n",
            " \n",
            "You are an experienced medical advisor.\n",
            "\n",
            "Based on the following context, answer the patient's question in simple and accurate terms:\n",
            "\n",
            "Context:\n",
            "There is as yet no consensus [HIGHLIGHT]on[/HIGHLIGHT] [HIGHLIGHT]how[/HIGHLIGHT] often patients should check [HIGHLIGHT]their[/HIGHLIGHT] blood glucose. It allows patients [HIGHLIGHT]to[/HIGHLIGHT] make [HIGHLIGHT]their[/HIGHLIGHT] own adjustments [HIGHLIGHT]to[/HIGHLIGHT] insulin dosages and helps [HIGHLIGHT]to[/HIGHLIGHT] avoid hypoglycemia. Self-monitoring of blood glucose has become an integral part of modern insulin treatment. [HIGHLIGHT]a[/HIGHLIGHT] registered dietician is best placed [HIGHLIGHT]to[/HIGHLIGHT] offer advice [HIGHLIGHT]on[/HIGHLIGHT] recommended diets.\n",
            "\n",
            "Question:\n",
            "Advise a diabetic patient on how to manage their condition while fasting during Ramadan.\n",
            "\n",
            "Answer:\n",
            "It is recommended that patients with diabetes fast for a shorter duration during Ramadan and consume a balanced meal after breaking their fast. This will help maintain stable blood glucose levels. Additionally, it is important to consult with a registered dietician to develop a personalized meal plan that takes into account any dietary restrictions or specific needs related to Ramadan fasting.\n",
            "\n",
            "üìö Retrieved Snippets:\n",
            "\n",
            "Source 1:\n",
            "must be started by hand. Self-monitoring of blood glucose has become an integral part of modern insulin treatment. It allows patients to make their own adjustments to insulin dosages and helps to avoid hypoglycemia. Self-monitoring increases the patients‚Äô role in their own management and gives a gre\n",
            "---\n",
            "Source 2:\n",
            "greater sense of being in control of their condition. There is as yet no consensus on how often patients should check their blood glucose, and the role of self-monitoring in type 2 diabetes mellitus remains in dispute TREATMENT Scobie Chapter 03 28/7/06 14:32 Page 53\n",
            "---\n",
            "Source 3:\n",
            "33 3T reatment DIETARY TREATMENT FOR TYPE 1 DIABETES MELLITUS An integral component of diabetes management by both the health-care professional and the patient with diabetes is the need to know the principles of dietary management of the condition. Nutrition is complex and a registered dietician is \n",
            "---\n",
            "Source 4:\n",
            "73 At diagnosis, all diabetic patients need immediate advice about what they should and should not eat. This may be given by the family physician, practice or specialist nurse, or hospital ward staff. It should be kept simple until a dietician can give more detailed recom- mendations (see Figure 74)\n",
            "---\n",
            "Source 5:\n",
            "recommendations to individual patients' needs, with special consideration of ethnic minorities Figure 74 The importance of diet in the treatment of diabetes cannot be overemphasized. Patients and their relatives should have open access to consultation with a professional dietician. The dietary princ\n",
            "---\n",
            "Source 6:\n",
            "their legends take the reader through this topic. What is the best way to treat patients with type 1 DM? An impor- tant step is to attempt to reproduce the normal fasting and post-prandial insulin profiles. How is this done and what insulin preparations are available to achieve it? Figures 50‚Äì62 pro\n",
            "---\n",
            "Source 7:\n",
            "34 ATLAS OF DIABETES MELLITUS DIETARY TREATMENT FOR TYPE 2 DIABETES MELLITUS Diet is the cornerstone of treatment of type 2 DM. Simple initial advice for calorie restriction and avoid- ance of sweet foods and drinks can lead to sympto- matic improvement and a fall in blood glucose levels before any \n",
            "---\n",
            "Source 8:\n",
            "type 1 DM from Australia has documented the exhibition of a broad range of psychiatric diagnoses 10 years after disease onset, with females and adoles- cents with pre-existing psychologic problems being at particular risk. Great skill by experienced teams comprising pedi- atric diabetic specialist n\n",
            "---\n",
            "Source 9:\n",
            "nurses, dieticians, pediatric endocrinologists and child psychologists is needed to coordinate the effort to help diabetic children and their parents manage the diabetic condition. Difficult behavioral problems do occur in some children including denial of the disease, manipulative behavior and deli\n",
            "---\n"
          ]
        }
      ]
    }
  ]
}